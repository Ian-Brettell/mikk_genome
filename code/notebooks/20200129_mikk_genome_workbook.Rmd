---
title: "MIKK Panel genome analysis workbook"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

# Plan

*20200203*

From meeting with Tom Fitzgerald on 26 November 2019:

• Introgression:
  - Create giant population VCF - choose the datasets. Just a case of merging some VCFs.
    - Get some Indonesian medaka
• LD decay:
  - LD plots - per chromosome.
  - Heatmap per chromosome?
• Fst plot  

# Setup

## Create directory structure and clone repo

Working directory here: `/hps/research1/birney/users/ian/mikk_paper`

```{bash}
# move to working directory
homehps
cd mikk_paper
# clone git repository
git clone https://github.com/Ian-Brettell/mikk_genome.git
# create directory for VCFs
mkdir vcfs
```

## Pull across MIKK Panel VCF

```{r}
cp /nfs/research1/birney/projects/medaka/inbred_panel/medaka-alignments-release-94/vcf/medaka_inbred_panel_ensembl_new_reference_release_94.vcf* vcfs
```

## Key file for cram ID to line ID

`mikk_genome/data/20200206_cram_id_to_line_id.txt`

## Remove duplicates and non-panel lines

```{bash}
# Find duplicates
ssh ebi
homehps
cd mikk_paper/mikk_genome/
cat data/20200206_cram_id_to_line_id.txt | cut -f2 | cut -f1 -d"_" | sort | uniq -d
```

Note the following duplicates:

-106
-11
-117
-131
-132
-134
-135
-138
-14
-140
-141
-15
-23
-32
-39
-4
-40
-49
-59
-69
-7
-71
-72
-80
-84

Only take _1 sibling from pair, unless what is ecluded is the only survivor based on `mikk_behaviour/data/panel_1/20200109_panel_lines.txt`.

*Query* whether we keep the lines that may have died out? Ask Felix.

## Key file for no sibs

`mikk_genome/data/20200206_cram2line_key_no-sibs.txt`

Excluded IDs: `mikk_genome/data/20200206_excluded_lines.txt`

*20200225*

Full list of MIKK lines from Felix here: `mikk_genome/data/20200210_panel_lines_full.txt`

```{bash}
cat ~/Documents/Repositories/mikk_genome/data/20200210_panel_lines_full.txt cut -f1 -d"-" | sort | uniq -d
```

- 106
- 11
- 117
- 131
- 132
- 135
- 14
- 140
- 23
- 39
- 4
- 40
- 59
- 69
- 72
- 80

List with no sibling lines here: `mikk_genome/data/20200227_panel_lines_no-sibs.txt`. 64 lines total.

Excluded IDs here: `mikk_genome/data/20200227_panel_lines_excluded.txt`. 16 lines total.

Replace all dashes with underscores to match cram2line key file
```{bash}
sed 's/-/_/g' data/20200227_panel_lines_no-sibs.txt > data/20200227_panel_lines_no-sibs_us.txt  
```

Extract the lines to keep from the key file.
```{bash}
awk  'FNR==NR {f1[$0]; next} $2 in f1' data/20200227_panel_lines_no-sibs_us.txt data/20200206_cram_id_to_line_id.txt > data/20200227_cram2line_no-sibs.txt
```

Has 66 lines instead of 63 (because we're missing 130-2), so there must be duplicates. Find out which ones:

```{bash}
cat data/20200227_cram2line_no-sibs.txt | cut -f2 | cut -f1 -d"_" | sort | uniq -d
```

32
71
84

Manually removed (`data/20200227_duplicates_excluded.txt`):

• 24271_7#5	32_2
• 24271_8#4	71_1
• 24259_1#1	84_2

Final version: `data/20200227_cram2line_no-sibs.txt`

Final version, cram IDs only:

# Create filtered VCF

## Rename samples using BCFTOOLS

```{bash}
# create list of CRAM IDs in VCF
bcftools query -l vcfs/medaka_inbred_panel_ensembl_new_reference_release_94.vcf > tmp.txt
# confirm that it's in the same order as the column in the line IDs file
cut -f1 mikk_genome/data/20200206_cram_id_to_line_id.txt | tail -n+2 > tmp2.txt
# bash script to compare
file1="tmp.txt"
file2="tmp2.txt"

if cmp -s "$file1" "$file2"; then
    printf 'The file "%s" is the same as "%s"\n' "$file1" "$file2"
else
    printf 'The file "%s" is different from "%s"\n' "$file1" "$file2"
fi
# clean up
rm tmp*

# create file with no header
tail -n+2 mikk_genome/data/20200206_cram_id_to_line_id.txt > mikk_genome/data/20200203_cram2line_no-header.txt
# replace tab with space
sed 's/\t/ /g' mikk_genome/data/20200203_cram2line_no-header.txt > tmp.txt
mv tmp.txt mikk_genome/data/20200203_cram2line_no-header.txt

# Rename samples with BCFTOOLS
bcftools reheader --output-file vcfs/panel_line-ids.vcf --samples mikk_genome/data/20200203_cram2line_no-header.txt vcfs/medaka_inbred_panel_ensembl_new_reference_release_94.vcf
# test
bcftools query -l  vcfs/panel_line-ids.vcf
#[E::bcf_hdr_add_sample] Duplicated sample name '84_2'
#[E::bcf_hdr_add_sample] Duplicated sample name '141_3'
#[E::bcf_hdr_add_sample] Duplicated sample name '32_2'
#[E::bcf_hdr_add_sample] Duplicated sample name '71_1'
#Failed to open vcfs/panel_line-ids.vcf: could not parse header

# create no-sibs file with CRAM ID only
cut -f1 mikk_genome/data/20200227_cram2line_no-sibs.txt > mikk_genome/data/20200227_cram2line_no-sibs_cram-only.txt
# pull out only samples to be included, then recode
bcftools view --output-file vcfs/panel_no-sibs.vcf --samples-file mikk_genome/data/20200227_cram2line_no-sibs_cram-only.txt vcfs/medaka_inbred_panel_ensembl_new_reference_release_94.vcf
# SUCCESS
# recode
bcftools reheader --output vcfs/panel_no-sibs_line-ids.vcf --samples mikk_genome/data/20200227_cram2line_no-sibs.txt vcfs/panel_no-sibs.vcf
# compress
## option 1: bgzip vcfs/panel_no-sibs_line-ids.vcf
## option 2:
bcftools view --output-type z --output-file vcfs/panel_no-sibs_line-ids.vcf.gz vcfs/panel_no-sibs_line-ids.vcf
# create index
bcftools index --tbi vcfs/panel_no-sibs_line-ids.vcf.gz
```

## Split by chromosome

### Get reference

```{bash}
mkdir refs

cp /nfs/research1/birney/projects/medaka/inbred_panel/medaka-alignments-release-94/ref/Oryzias_latipes.ASM223467v1* refs/
```

### Split by chromosome
```{bash}
mkdir vcfs/split_by_chr

for i in $(seq 1 24); do
  bsub -o log/split_by_chr_$i.out -e log/split_by_chr_$i.err \
  "bcftools filter \
    --regions $i \
    --output-type z \
    --output vcfs/split_by_chr/panel_no-sibs_chr-$i.vcf.gz \
    vcfs/panel_no-sibs_line-ids.vcf.gz";
  done  
```

## Recode into 012 genotypes

```{r}

```



